# API Keys
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# LLM Configuration
LLM_PROVIDER=openai  # 'openai' or 'anthropic'
LLM_MODEL=gpt-4-turbo-preview  # or 'claude-3-opus-20240229'
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=2000

# Embedding Configuration
EMBEDDING_PROVIDER=local  # 'openai' or 'local' (local is free, uses sentence-transformers)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small  # or 'text-embedding-3-large'
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2  # or 'all-mpnet-base-v2' for better quality

# Vector Search
VECTOR_SEARCH_K=5

# Deep Learning Models
DL_MODEL_NAME=microsoft/codebert-base
DL_BATCH_SIZE=8  # CPU-optimized batch size
DL_MAX_LENGTH=512
USE_ONNX=false  # Set to true for faster CPU inference (requires onnxruntime)

# Static Analysis Tools
ENABLE_BANDIT=true
ENABLE_SEMGREP=true
ENABLE_PYLINT=false  # Can be slow
ENABLE_RUFF=true  # Very fast Python linter

# Feature Flags
ENABLE_ML_ANALYSIS=true
ENABLE_DL_ANALYSIS=false  # CPU intensive, set to true if you want deep learning analysis
ENABLE_LLM_AGENTS=true
ENABLE_SEMANTIC_SEARCH=true

# Performance
MAX_WORKERS=4
CACHE_EMBEDDINGS=true

# Logging
LOG_LEVEL=INFO

# Risk Thresholds
RISK_THRESHOLD_HIGH=0.7
RISK_THRESHOLD_MEDIUM=0.4
CONFIDENCE_THRESHOLD=0.6
